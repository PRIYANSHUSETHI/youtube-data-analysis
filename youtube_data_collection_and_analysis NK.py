# -*- coding: utf-8 -*-
"""youtube data collection and analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L_xuV3Wxo2JkNxxrCTlIRbC7wYYU6kMR
"""

import pandas as pd
from googleapiclient.discovery import build

api_key = 'YOUR_API_KEY'

def get_trending_videos(api_key, max_results = 200):
  #building the youtube service
  youtube = build('youtube', 'v3', developerKey= api_key)

  #initialise the list to hold the details of the videos
  videos = []

  #fetching most popular videos
  request = youtube.videos().list(
      part = 'snippet,contentDetails,statistics',
      chart = 'mostPopular',
      regionCode = 'US',
      maxResults = 50
  )

  while request and len(videos) < max_results:
    response = request.execute()
    for item in response['items']:
      video_details = {
          'video_id': item['id'],
                'title': item['snippet']['title'],
                'description': item['snippet']['description'],
                'published_at': item['snippet']['publishedAt'],
                'channel_id': item['snippet']['channelId'],
                'channel_title': item['snippet']['channelTitle'],
                'category_id': item['snippet']['categoryId'],
                'tags': item['snippet'].get('tags', []),
                'duration': item['contentDetails']['duration'],
                'definition': item['contentDetails']['definition'],
                'caption': item['contentDetails'].get('caption', 'false'),
                'view_count': item['statistics'].get('viewCount', 0),
                'like_count': item['statistics'].get('likeCount', 0),
                'dislike_count': item['statistics'].get('dislikeCount', 0),
                'favorite_count': item['statistics'].get('favoriteCount', 0),
                'comment_count': item['statistics'].get('commentCount', 0)
      }

      videos.append(video_details)

    request = youtube.videos().list_next(request,response)

  return videos[:max_results]

def save_to_csv(data, filename):
  df = pd.DataFrame(data)
  df.to_csv(filename, index = False)


def main():
  trending_videos = get_trending_videos(api_key)
  filename = 'trending_videos.csv'
  save_to_csv(trending_videos, filename)
  print(f'Trending Videos saved to{filename}')

if __name__ == '__main__':
    main()

"""BREAKDOWN OF THE CODE ABOVE :

Breakdown of the Code
1) Imports Required Libraries

2) googleapiclient.discovery.build is used to interact with the YouTube Data API.

3) The script includes an API key (api_key), which is required to authenticate requests to the YouTube API.

4) Fetches trending videos from YouTube's "mostPopular" category for the US region (regionCode='US').
Uses the YouTube Data API to retrieve video details in batches of 50 (the API's max limit per request).

5) Extracts key details for each video, such as:
video_id, title, description, published_at, channel_id, channel_title
category_id, tags, duration, definition, caption
view_count, like_count, dislike_count, favorite_count, comment_count
The script uses pagination to fetch up to max_results videos.
save_to_csv(data, filename)

6) Converts the collected video data into a Pandas DataFrame and saves it to a CSV file (trending_videos.csv).
main() Function

7) Calls get_trending_videos() to fetch the data.
Calls save_to_csv() to store the data in trending_videos.csv.
Prints a confirmation message.

8)Execution (if __name__ == '__main__':)
Ensures the script runs only when executed directly.
Calls main().

LET'S HAVE A LOOK AT HOW THE DATA LOOK
"""

import pandas as pd

trending_videos = pd.read_csv('trending_videos.csv')
print(trending_videos.head)

"""CHECKING FOR ANY MISSING VALUES

"""

missing_values = trending_videos.isnull().sum()
missing_values

"""WE CAN SEE THAT THE COLUMN DESCRIPTION HAS A MISSING VALUE, WE WILL FILL THOSE ENTRIES WITH "NO DESCRIPTION"
"""

trending_videos['description'].fillna('No Description', inplace = True)

trending_videos.dtypes

"""WE WILL NOW CONVERT PUBLISHED_AT FIELDS TO DATE_TIME DATATYPE"""

trending_videos['published_at'] = pd.to_datetime(trending_videos['published_at'])

"""AND CONVERT TAGS ON A VIDEO TO A LIST"""

trending_videos['tags'] = trending_videos['tags'].apply(lambda x: eval(x) if isinstance(x, str) else x)

"""BEFORE MOVING FORWARD LET US HAVE A QUICK LOOK AT THE DESCRIPTIVE ANALYSIS OF THE DATASET THAT WE HAVE FOR OUR ANALYSIS"""

trending_videos.describe()

"""LET US HAVE A LOOK AT THE DISTRIBUTION OF VIEWS, LIKES AND COMMENTS OF ALL THE DIFFERENT VIDEOS"""

import matplotlib.pyplot as plt
import seaborn as sns
sns.set(style = 'whitegrid')

fig, axes = plt.subplots(1,3, figsize= (18,5))

#VIEWING COUNT DISTRIBUTION
sns.histplot(trending_videos['view_count'],bins = 30, kde = True, ax= axes[0], color = 'blue')
axes[0].set_title('View Count Distribution')
axes[0].set_xlabel('View Counts')
axes[0].set_ylabel('Frequency')

#VIEWING LIKES DISTRIBUTION
sns.histplot(trending_videos['like_count'],bins = 30, kde = True, ax= axes[1], color = 'green')
axes[1].set_title('Likes Count Distribution')
axes[1].set_xlabel('Like Counts')
axes[1].set_ylabel('Frequency')

#VIEWING COMMENTS DITRIBUTION
sns.histplot(trending_videos['comment_count'],bins = 30, kde = True, ax= axes[2], color = 'blue')
axes[2].set_title('Comment Count Distribution')
axes[2].set_xlabel('Comment Counts')
axes[2].set_ylabel('Frequency')

"""WE CAN SEE THAT THE DISTRIBUTION OF EACH OF THE PARAMETERS IS RIGHT SKEWED. IT WOULD BE INTRESTING TO SEE HOW THESE PARAMETERS ARE CORELATED.

LET US NOW CREATE A CORRELATION MATRIX FOR THE PARAMETERS.
"""

correlation_matrix = trending_videos[['view_count','like_count','comment_count']].corr()

# LET US NOW PLOT THE CORRELATION MATRIX USING A HEATMAP
plt.figure(figsize = (8,6))
sns.heatmap(correlation_matrix, annot = True, cmap = 'coolwarm', fmt = '.2f')
plt.title('Correlation Matrix of the engagement metric')
plt.show()

"""THE ABOVE CORRELATION MATRIX CONFIRMS HIGH CORRELATION BETWEEN THE COUNT OF LIKES, COMMENTS AND VIEWS

LET US NOW ALSO FIND THE CATEGORIES OF THE VIDEOS THAT ARE PART OF OUR DATASET AND ANALYSE THE DIFFERENT PARAMETERS WITH RESEPECT TO EACH CATEGORY
"""

from googleapiclient.discovery import build
API_KEY = 'YOUR_API_KEY'
youtube = build('youtube','v3', developerKey = API_KEY)
def get_category_mapping():
  request = youtube.videoCategories().list(
      part = 'snippet',
      regionCode = 'US'
  )

  response = request.execute()
  category_mapping ={}
  for item in response['items']:
    category_id = int(item['id'])
    category_name = item['snippet']['title']
    category_mapping[category_id] = category_name
  return category_mapping

category_mapping = get_category_mapping()
category_mapping

"""LET US NOW ANALYSE THE THE NUMBER OF TREDNING VIDEOS BY CATEGORY"""

trending_videos['category_name'] = trending_videos['category_id'].map(category_mapping)
#LET US NOW CREATE A BAR CHART FOR CATEGORY COUNTS
plt.figure(figsize=(12,8))
sns.countplot(y = trending_videos['category_name'], order= trending_videos['category_name'].value_counts().index, palette = 'viridis')
plt.title('Number of Trending Videos by Category')
plt.xlabel('Number of Videos')
plt.ylabel('Category')
plt.show()

#AVERAGE ENGAGEMENT METRICS BY CATEGORY
category_engagement = trending_videos.groupby('category_name')[['view_count', 'like_count', 'comment_count']].mean().sort_values(by='view_count', ascending=False)

fig, axes = plt.subplots(1, 3, figsize=(15, 10))

# VIEW COUNT BY CATEGORY
sns.barplot(y=category_engagement.index, x=category_engagement['view_count'], ax=axes[0], palette='viridis')
axes[0].set_title('Average View Count by Category')
axes[0].set_xlabel('Average View Count')
axes[0].set_ylabel('Category')

# LIKE COUNT BY CATEGORY
sns.barplot(y=category_engagement.index, x=category_engagement['like_count'], ax=axes[1], palette='viridis')
axes[1].set_title('Average Like Count by Category')
axes[1].set_xlabel('Average Like Count')
axes[1].set_ylabel('')

# COMMENT COUNT BY CATEGORY
sns.barplot(y=category_engagement.index, x=category_engagement['comment_count'], ax=axes[2], palette='viridis')
axes[2].set_title('Average Comment Count by Category')
axes[2].set_xlabel('Average Comment Count')
axes[2].set_ylabel('')

plt.tight_layout()
plt.show()

"""NOW LET US ANALYZE THE CONTENT AND DURATION OF THE VIDEOS. BUT FIRST WE NEED TO CONVERT THE DURATION FROM ISO 8601 FORMAT TO SECONDS."""

!pip install isodate
import isodate
import pandas as pd

# Assuming trending_videos is your DataFrame

def parse_duration(duration_str):
    """Parses duration string, handling both ISO 8601 and numeric formats."""
    try:
        # Attempt to parse as ISO 8601 duration
        return isodate.parse_duration(duration_str).total_seconds()
    except isodate.ISO8601Error:
        # If ISO 8601 parsing fails, try converting to float
        try:
            return float(duration_str)
        except ValueError:
            # If conversion to float fails, return NaN
            return float('nan')

trending_videos['duration_seconds'] = trending_videos['duration'].astype(str).apply(parse_duration)

# Now, proceed with creating the duration range:
trending_videos['duration_range'] = pd.cut(
    trending_videos['duration_seconds'],
    bins=[0, 300, 600, 1200, 3600, 7200],
    labels=['0-5 min', '5-10 min', '10-20 min', '20-60 min', '60-120 min']
)

"""WE USE THE ISODATE LIBRARY TO CONVERT VIDEO DURATIONS FROM ISO 8601 FORMAT TO SECONDS FOR NUMERICAL ANALYSIS. AFTER CONVERSION, VIDEOS ARE CATEGORIZED INTO DURATION RANGES (0-5, 5-10, 10-20, 20-60, 60-120 MINUTES) IN A NEW COLUMN DURATION_RANGE. THIS HELPS ANALYZE ENGAGEMENT METRICS BASED ON VIDEO LENGTH PROVIDING INSIGHTS INTO VIEWER BEHAVIOR AND PERFORMANCE.

ANALYSING THE CONTENT BASED ON DURATION
"""

#SCATTER PLOT FOR VIDEO LENGTH VS VIEW COUNT
plt.figure(figsize=(10, 6))
sns.scatterplot(x='duration_seconds', y='view_count', data=trending_videos, alpha=0.6, color='purple')
plt.title('Video Length vs View Count')
plt.xlabel('Video Length (seconds)')
plt.ylabel('View Count')
plt.show()

#BAR CHART FOR ENGAGEMENT METRICS BY DURATION RANGE
length_engagement = trending_videos.groupby('duration_range')[['view_count', 'like_count', 'comment_count']].mean()

fig, axes = plt.subplots(1, 3, figsize=(18, 8))

# VIEW COUNT BY DURATION RANGE
sns.barplot(y=length_engagement.index, x=length_engagement['view_count'], ax=axes[0], palette='magma')
axes[0].set_title('Average View Count by Duration Range')
axes[0].set_xlabel('Average View Count')
axes[0].set_ylabel('Duration Range')

# LIKE COUNT BY DURATION RANGE
sns.barplot(y=length_engagement.index, x=length_engagement['like_count'], ax=axes[1], palette='magma')
axes[1].set_title('Average Like Count by Duration Range')
axes[1].set_xlabel('Average Like Count')
axes[1].set_ylabel('')

# COMMENT COUNT BY DURATION RANGE
sns.barplot(y=length_engagement.index, x=length_engagement['comment_count'], ax=axes[2], palette='magma')
axes[2].set_title('Average Comment Count by Duration Range')
axes[2].set_xlabel('Average Comment Count')
axes[2].set_ylabel('')

plt.tight_layout()
plt.show()

"""RELATIONSHIP BETWEEN VIEWS AND NUMBER OF TAGS"""

# CALCULATE THE NUMBER OF TAGS FOR EACH VIDEO
trending_videos['tag_count'] = trending_videos['tags'].apply(len)

# SCATTER PLOIT FOR NUMBER OF TAGS VS VIEW COUNT
plt.figure(figsize=(10, 6))
sns.scatterplot(x='tag_count', y='view_count', data=trending_videos, alpha=0.6, color='orange')
plt.title('Number of Tags vs View Count')
plt.xlabel('Number of Tags')
plt.ylabel('View Count')
plt.show()

"""LET US NOW TRY TO UNDERSTAND THE IMPACT OF TIME OF POSTING OF A VIDEO ON THE NUMBER OF VIEWS IT HAS

"""

# EXTRTACTING THE HOUR FROM THE TIME OF PUBLISHING THE VIDEO
trending_videos['publish_hour'] = trending_videos['published_at'].dt.hour

# PLOTTING THE RESULT IN THE FORM OF A BAR CHART
plt.figure(figsize=(12, 6))
sns.countplot(x='publish_hour', data=trending_videos, palette='coolwarm')
plt.title('Distribution of Videos by Publish Hour')
plt.xlabel('Publish Hour')
plt.ylabel('Number of Videos')
plt.show()

# SCATTER PLOT FOR PUBLISH HOUR VS VIEW COUNT
plt.figure(figsize=(10, 6))
sns.scatterplot(x='publish_hour', y='view_count', data=trending_videos, alpha=0.6, color='teal')
plt.title('Publish Hour vs View Count')
plt.xlabel('Publish Hour')
plt.ylabel('View Count')
plt.show()

